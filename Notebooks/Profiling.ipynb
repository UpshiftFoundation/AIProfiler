{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bdb1007cff174672aad23d14cbb1c818": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3c4424abb80e4edfb37b37f70611fda7",
              "IPY_MODEL_11ca8f350e944755ad1a6b1cc7db2ec6",
              "IPY_MODEL_4c1657f8370c436cbf219654ec1d2abd"
            ],
            "layout": "IPY_MODEL_2cf862b2c86841a8be68c65c80e8de9d"
          }
        },
        "3c4424abb80e4edfb37b37f70611fda7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2cb054b59f74519b33275e230f40026",
            "placeholder": "​",
            "style": "IPY_MODEL_14b4759a08ce4de798bf42df908332d5",
            "value": "100%"
          }
        },
        "11ca8f350e944755ad1a6b1cc7db2ec6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7add3c06789414eb0726547b3c9b9c8",
            "max": 32342954,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_56db207cd7d040929f13bbdd8aaaf381",
            "value": 32342954
          }
        },
        "4c1657f8370c436cbf219654ec1d2abd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8f4940dcc5146a5963af31f7c685126",
            "placeholder": "​",
            "style": "IPY_MODEL_076df2e8c9304f26be31c4496bc32bec",
            "value": " 30.8M/30.8M [00:00&lt;00:00, 83.4MB/s]"
          }
        },
        "2cf862b2c86841a8be68c65c80e8de9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2cb054b59f74519b33275e230f40026": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14b4759a08ce4de798bf42df908332d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7add3c06789414eb0726547b3c9b9c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56db207cd7d040929f13bbdd8aaaf381": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d8f4940dcc5146a5963af31f7c685126": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "076df2e8c9304f26be31c4496bc32bec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldv58BFdHjKH"
      },
      "source": [
        "\n",
        "# PyTorch Profiler\n",
        "This recipe explains how to use PyTorch profiler and measure the time and\n",
        "memory consumption of the model's operators.\n",
        "\n",
        "## Introduction\n",
        "PyTorch includes a simple profiler API that is useful when user needs\n",
        "to determine the most expensive operators in the model.\n",
        "\n",
        "In this recipe, we will use a simple Resnet model to demonstrate how to\n",
        "use profiler to analyze model performance.\n",
        "\n",
        "## Setup\n",
        "To install ``torch`` and ``torchvision`` use the following command:\n",
        "\n",
        "::\n",
        "\n",
        "   pip install torch torchvision\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RV9y8NgHjKO"
      },
      "source": [
        "## Steps\n",
        "\n",
        "1. Import all necessary libraries\n",
        "2. Instantiate a simple Resnet model\n",
        "3. Using profiler to analyze execution time\n",
        "4. Using profiler to analyze memory consumption\n",
        "5. Using tracing functionality\n",
        "6. Examining stack traces\n",
        "7. Visualizing data as a flamegraph\n",
        "8. Using profiler to analyze long-running jobs\n",
        "\n",
        "### 1. Import all necessary libraries\n",
        "\n",
        "In this recipe we will use ``torch``, ``torchvision.models``\n",
        "and ``profiler`` modules:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1-1epukHjKR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "from torch.profiler import profile, record_function, ProfilerActivity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-hSamKpHjKX"
      },
      "source": [
        "### 2. Instantiate a simple Resnet model\n",
        "\n",
        "Let's create an instance of a Resnet model and prepare an input\n",
        "for it:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRhuauJoHjKc"
      },
      "outputs": [],
      "source": [
        "model = models.resnet18()\n",
        "inputs = torch.randn(5, 3, 224, 224)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXiNUErpHjKf"
      },
      "source": [
        "### 3. Using profiler to analyze execution time\n",
        "\n",
        "PyTorch profiler is enabled through the context manager and accepts\n",
        "a number of parameters, some of the most useful are:\n",
        "\n",
        "- ``activities`` - a list of activities to profile:\n",
        "   - ``ProfilerActivity.CPU`` - PyTorch operators, TorchScript functions and\n",
        "     user-defined code labels (see ``record_function`` below);\n",
        "   - ``ProfilerActivity.CUDA`` - on-device CUDA kernels;\n",
        "- ``record_shapes`` - whether to record shapes of the operator inputs;\n",
        "- ``profile_memory`` - whether to report amount of memory consumed by\n",
        "  model's Tensors;\n",
        "- ``use_cuda`` - whether to measure execution time of CUDA kernels.\n",
        "\n",
        "Note: when using CUDA, profiler also shows the runtime CUDA events\n",
        "occuring on the host.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5BV8TUhHjKh"
      },
      "source": [
        "Let's see how we can use profiler to analyze the execution time:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LagCzVr2HjKk"
      },
      "outputs": [],
      "source": [
        "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
        "    with record_function(\"model_inference\"):\n",
        "        model(inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vbrvmATHjKn"
      },
      "source": [
        "Note that we can use ``record_function`` context manager to label\n",
        "arbitrary code ranges with user provided names\n",
        "(``model_inference`` is used as a label in the example above).\n",
        "\n",
        "Profiler allows one to check which operators were called during the\n",
        "execution of a code range wrapped with a profiler context manager.\n",
        "If multiple profiler ranges are active at the same time (e.g. in\n",
        "parallel PyTorch threads), each profiling context manager tracks only\n",
        "the operators of its corresponding range.\n",
        "Profiler also automatically profiles the async tasks launched\n",
        "with ``torch.jit._fork`` and (in case of a backward pass)\n",
        "the backward pass operators launched with ``backward()`` call.\n",
        "\n",
        "Let's print out the stats for the execution above:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isyHpCPSHjKq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89df3bfd-2ded-46d4-f20d-a27b4ad69cba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
            "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                  model_inference         3.00%      14.840ms        99.47%     491.531ms     491.531ms             1  \n",
            "                     aten::conv2d         0.06%     321.000us        64.97%     321.039ms      16.052ms            20  \n",
            "                aten::convolution         0.58%       2.875ms        64.90%     320.718ms      16.036ms            20  \n",
            "               aten::_convolution         0.57%       2.828ms        64.32%     317.843ms      15.892ms            20  \n",
            "         aten::mkldnn_convolution        63.69%     314.715ms        63.75%     315.015ms      15.751ms            20  \n",
            "                 aten::batch_norm         0.02%      78.000us        11.75%      58.056ms       2.903ms            20  \n",
            "     aten::_batch_norm_impl_index         0.72%       3.560ms        11.73%      57.978ms       2.899ms            20  \n",
            "          aten::native_batch_norm        10.96%      54.160ms        11.01%      54.388ms       2.719ms            20  \n",
            "                 aten::max_pool2d         0.01%      25.000us         9.92%      49.014ms      49.014ms             1  \n",
            "    aten::max_pool2d_with_indices         9.91%      48.989ms         9.91%      48.989ms      48.989ms             1  \n",
            "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 494.141ms\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcdA03UlHjKx"
      },
      "source": [
        "Here we see that, as expected, most of the time is spent in convolution (and specifically in ``mkldnn_convolution``\n",
        "for PyTorch compiled with MKL-DNN support).\n",
        "Note the difference between self cpu time and cpu time - operators can call other operators, self cpu time excludes time\n",
        "spent in children operator calls, while total cpu time includes it. You can choose to sort by the self cpu time by passing\n",
        "``sort_by=\"self_cpu_time_total\"`` into the ``table`` call.\n",
        "\n",
        "To get a finer granularity of results and include operator input shapes, pass ``group_by_input_shape=True``\n",
        "(note: this requires running the profiler with ``record_shapes=True``):\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydXGvun9HjKx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bd65633-7e03-4306-fcf7-9a6ee69688f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
            "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls                                                                      Input Shapes  \n",
            "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
            "                  model_inference         1.29%       5.899ms        99.99%     458.027ms     458.027ms             1                                                                                []  \n",
            "                     aten::conv2d         0.01%      37.000us        18.35%      84.065ms      21.016ms             4                             [[5, 64, 56, 56], [64, 64, 3, 3], [], [], [], [], []]  \n",
            "                aten::convolution         0.02%     108.000us        18.34%      84.028ms      21.007ms             4                     [[5, 64, 56, 56], [64, 64, 3, 3], [], [], [], [], [], [], []]  \n",
            "               aten::_convolution         0.02%      73.000us        18.32%      83.920ms      20.980ms             4     [[5, 64, 56, 56], [64, 64, 3, 3], [], [], [], [], [], [], [], [], [], [], []]  \n",
            "         aten::mkldnn_convolution        18.27%      83.697ms        18.30%      83.847ms      20.962ms             4                             [[5, 64, 56, 56], [64, 64, 3, 3], [], [], [], [], []]  \n",
            "                     aten::conv2d         0.01%      24.000us        13.23%      60.595ms      20.198ms             3                            [[5, 512, 7, 7], [512, 512, 3, 3], [], [], [], [], []]  \n",
            "                aten::convolution         0.02%      73.000us        13.22%      60.571ms      20.190ms             3                    [[5, 512, 7, 7], [512, 512, 3, 3], [], [], [], [], [], [], []]  \n",
            "               aten::_convolution         0.01%      49.000us        13.21%      60.498ms      20.166ms             3    [[5, 512, 7, 7], [512, 512, 3, 3], [], [], [], [], [], [], [], [], [], [], []]  \n",
            "         aten::mkldnn_convolution        13.18%      60.386ms        13.20%      60.449ms      20.150ms             3                            [[5, 512, 7, 7], [512, 512, 3, 3], [], [], [], [], []]  \n",
            "                     aten::conv2d         0.01%      27.000us        12.65%      57.951ms      19.317ms             3                          [[5, 128, 28, 28], [128, 128, 3, 3], [], [], [], [], []]  \n",
            "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
            "Self CPU time total: 458.071ms\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(prof.key_averages(group_by_input_shape=True).table(sort_by=\"cpu_time_total\", row_limit=10))\n",
        "\n",
        "# (omitting some columns)\n",
        "# ---------------------------------  ------------  -------------------------------------------\n",
        "#                              Name     CPU total                                 Input Shapes\n",
        "# ---------------------------------  ------------  -------------------------------------------\n",
        "#                   model_inference      57.503ms                                           []\n",
        "#                      aten::conv2d       8.008ms      [5,64,56,56], [64,64,3,3], [], ..., []]\n",
        "#                 aten::convolution       7.956ms     [[5,64,56,56], [64,64,3,3], [], ..., []]\n",
        "#                aten::_convolution       7.909ms     [[5,64,56,56], [64,64,3,3], [], ..., []]\n",
        "#          aten::mkldnn_convolution       7.834ms     [[5,64,56,56], [64,64,3,3], [], ..., []]\n",
        "#                      aten::conv2d       6.332ms    [[5,512,7,7], [512,512,3,3], [], ..., []]\n",
        "#                 aten::convolution       6.303ms    [[5,512,7,7], [512,512,3,3], [], ..., []]\n",
        "#                aten::_convolution       6.273ms    [[5,512,7,7], [512,512,3,3], [], ..., []]\n",
        "#          aten::mkldnn_convolution       6.233ms    [[5,512,7,7], [512,512,3,3], [], ..., []]\n",
        "#                      aten::conv2d       4.751ms  [[5,256,14,14], [256,256,3,3], [], ..., []]\n",
        "# ---------------------------------  ------------  -------------------------------------------\n",
        "# Self CPU time total: 57.549ms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phzQTqLQHjKy"
      },
      "source": [
        "Note the occurence of ``aten::convolution`` twice with different input shapes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQpkBeDuHjKz"
      },
      "source": [
        "Profiler can also be used to analyze performance of models executed on GPUs:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzmZL5V2HjK1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "159ac51c-c38d-4eaf-f9d3-15fbc536d70c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                        model_inference         0.04%       2.785ms       100.00%        6.348s        6.348s       0.000us         0.00%       9.899ms       9.899ms             1  \n",
            "                                           aten::conv2d         0.00%      77.000us        93.88%        5.960s     297.995ms       0.000us         0.00%       8.047ms     402.350us            20  \n",
            "                                      aten::convolution         0.00%     245.000us        93.88%        5.960s     297.991ms       0.000us         0.00%       8.047ms     402.350us            20  \n",
            "                                     aten::_convolution         0.00%     201.000us        93.88%        5.960s     297.978ms       0.000us         0.00%       8.047ms     402.350us            20  \n",
            "                                aten::cudnn_convolution         9.22%     585.177ms        93.88%        5.959s     297.968ms       8.047ms        81.29%       8.047ms     402.350us            20  \n",
            "volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148...         0.00%       0.000us         0.00%       0.000us       0.000us       5.466ms        55.22%       5.466ms     420.462us            13  \n",
            "                                       aten::batch_norm         0.00%      50.000us         5.24%     332.721ms      16.636ms       0.000us         0.00%       1.020ms      51.000us            20  \n",
            "                           aten::_batch_norm_impl_index         0.00%     126.000us         5.24%     332.671ms      16.634ms       0.000us         0.00%       1.020ms      51.000us            20  \n",
            "                                 aten::cudnn_batch_norm         0.26%      16.582ms         5.24%     332.545ms      16.627ms       1.020ms        10.30%       1.020ms      51.000us            20  \n",
            "                   volta_scudnn_128x64_relu_small_nn_v1         0.00%       0.000us         0.00%       0.000us       0.000us     608.000us         6.14%     608.000us     608.000us             1  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 6.348s\n",
            "Self CUDA time total: 9.899ms\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model = models.resnet18().cuda()\n",
        "inputs = torch.randn(5, 3, 224, 224).cuda()\n",
        "\n",
        "with profile(activities=[\n",
        "        ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
        "    with record_function(\"model_inference\"):\n",
        "        model(inputs)\n",
        "\n",
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7fEMvtEHjK2"
      },
      "source": [
        "(Note: the first use of CUDA profiling may bring an extra overhead.)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lItoka9aHjK6"
      },
      "source": [
        "Note the occurence of on-device kernels in the output (e.g. ``sgemm_32x32x32_NN``).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGMufWk8HjK7"
      },
      "source": [
        "### 4. Using profiler to analyze memory consumption\n",
        "\n",
        "PyTorch profiler can also show the amount of memory (used by the model's tensors)\n",
        "that was allocated (or released) during the execution of the model's operators.\n",
        "In the output below, 'self' memory corresponds to the memory allocated (released)\n",
        "by the operator, excluding the children calls to the other operators.\n",
        "To enable memory profiling functionality pass ``profile_memory=True``.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-NpO8tsHjK8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a748b19e-edeb-4d73-85e6-dc5cba02d49e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
            "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                      aten::empty         0.14%     450.000us         0.14%     450.000us       2.250us      94.83 Mb      94.83 Mb           200  \n",
            "    aten::max_pool2d_with_indices        10.77%      34.505ms        10.77%      34.505ms      34.505ms      11.48 Mb      11.48 Mb             1  \n",
            "                     aten::conv2d         5.20%      16.673ms        67.06%     214.836ms      10.742ms      47.37 Mb       3.83 Mb            20  \n",
            "                      aten::addmm         0.14%     443.000us         0.14%     459.000us     459.000us      19.53 Kb      19.53 Kb             1  \n",
            "                       aten::mean         0.01%      31.000us         0.06%     199.000us     199.000us      10.00 Kb      10.00 Kb             1  \n",
            "              aten::empty_strided         0.00%       5.000us         0.00%       5.000us       5.000us           4 b           4 b             1  \n",
            "                aten::convolution         0.09%     288.000us        67.02%     214.719ms      10.736ms      47.37 Mb           0 b            20  \n",
            "               aten::_convolution         0.06%     188.000us        66.93%     214.431ms      10.722ms      47.37 Mb           0 b            20  \n",
            "         aten::mkldnn_convolution        66.79%     213.960ms        66.88%     214.243ms      10.712ms      47.37 Mb           0 b            20  \n",
            "                aten::as_strided_         0.02%      49.000us         0.02%      49.000us       2.450us           0 b           0 b            20  \n",
            "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 320.360ms\n",
            "\n",
            "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
            "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                      aten::empty         0.14%     450.000us         0.14%     450.000us       2.250us      94.83 Mb      94.83 Mb           200  \n",
            "                 aten::batch_norm         0.02%      63.000us        15.25%      48.863ms       2.443ms      47.41 Mb           0 b            20  \n",
            "     aten::_batch_norm_impl_index         0.05%     156.000us        15.23%      48.800ms       2.440ms      47.41 Mb           0 b            20  \n",
            "          aten::native_batch_norm        15.09%      48.355ms        15.18%      48.623ms       2.431ms      47.41 Mb     -52.25 Kb            20  \n",
            "                     aten::conv2d         5.20%      16.673ms        67.06%     214.836ms      10.742ms      47.37 Mb       3.83 Mb            20  \n",
            "                aten::convolution         0.09%     288.000us        67.02%     214.719ms      10.736ms      47.37 Mb           0 b            20  \n",
            "               aten::_convolution         0.06%     188.000us        66.93%     214.431ms      10.722ms      47.37 Mb           0 b            20  \n",
            "         aten::mkldnn_convolution        66.79%     213.960ms        66.88%     214.243ms      10.712ms      47.37 Mb           0 b            20  \n",
            "                 aten::empty_like         0.02%      73.000us         0.06%     178.000us       8.900us      47.37 Mb           0 b            20  \n",
            "                 aten::max_pool2d         0.00%       9.000us        10.77%      34.514ms      34.514ms      11.48 Mb           0 b             1  \n",
            "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 320.360ms\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model = models.resnet18()\n",
        "inputs = torch.randn(5, 3, 224, 224)\n",
        "\n",
        "with profile(activities=[ProfilerActivity.CPU],\n",
        "        profile_memory=True, record_shapes=True) as prof:\n",
        "    model(inputs)\n",
        "\n",
        "print(prof.key_averages().table(sort_by=\"self_cpu_memory_usage\", row_limit=10))\n",
        "\n",
        "# (omitting some columns)\n",
        "# ---------------------------------  ------------  ------------  ------------\n",
        "#                              Name       CPU Mem  Self CPU Mem    # of Calls\n",
        "# ---------------------------------  ------------  ------------  ------------\n",
        "#                       aten::empty      94.79 Mb      94.79 Mb           121\n",
        "#     aten::max_pool2d_with_indices      11.48 Mb      11.48 Mb             1\n",
        "#                       aten::addmm      19.53 Kb      19.53 Kb             1\n",
        "#               aten::empty_strided         572 b         572 b            25\n",
        "#                     aten::resize_         240 b         240 b             6\n",
        "#                         aten::abs         480 b         240 b             4\n",
        "#                         aten::add         160 b         160 b            20\n",
        "#               aten::masked_select         120 b         112 b             1\n",
        "#                          aten::ne         122 b          53 b             6\n",
        "#                          aten::eq          60 b          30 b             2\n",
        "# ---------------------------------  ------------  ------------  ------------\n",
        "# Self CPU time total: 53.064ms\n",
        "\n",
        "print(prof.key_averages().table(sort_by=\"cpu_memory_usage\", row_limit=10))\n",
        "\n",
        "# (omitting some columns)\n",
        "# ---------------------------------  ------------  ------------  ------------\n",
        "#                              Name       CPU Mem  Self CPU Mem    # of Calls\n",
        "# ---------------------------------  ------------  ------------  ------------\n",
        "#                       aten::empty      94.79 Mb      94.79 Mb           121\n",
        "#                  aten::batch_norm      47.41 Mb           0 b            20\n",
        "#      aten::_batch_norm_impl_index      47.41 Mb           0 b            20\n",
        "#           aten::native_batch_norm      47.41 Mb           0 b            20\n",
        "#                      aten::conv2d      47.37 Mb           0 b            20\n",
        "#                 aten::convolution      47.37 Mb           0 b            20\n",
        "#                aten::_convolution      47.37 Mb           0 b            20\n",
        "#          aten::mkldnn_convolution      47.37 Mb           0 b            20\n",
        "#                  aten::max_pool2d      11.48 Mb           0 b             1\n",
        "#     aten::max_pool2d_with_indices      11.48 Mb      11.48 Mb             1\n",
        "# ---------------------------------  ------------  ------------  ------------\n",
        "# Self CPU time total: 53.064ms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYJLqv3FHjK-"
      },
      "source": [
        "### 5. Using tracing functionality\n",
        "\n",
        "Profiling results can be outputted as a .json trace file:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOj0C3AnHjK_"
      },
      "outputs": [],
      "source": [
        "model = models.resnet18().cuda()\n",
        "inputs = torch.randn(5, 3, 224, 224).cuda()\n",
        "\n",
        "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA]) as prof:\n",
        "    model(inputs)\n",
        "\n",
        "prof.export_chrome_trace(\"trace.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3PwsSnBHjLA"
      },
      "source": [
        "You can examine the sequence of profiled operators and CUDA kernels\n",
        "in Chrome trace viewer (``chrome://tracing``):\n",
        "\n",
        "<img src=\"file://../../_static/img/trace_img.png\" scale=\"25 %\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlrdRb6JHjLB"
      },
      "source": [
        "### 6. Examining stack traces\n",
        "\n",
        "Profiler can be used to analyze Python and TorchScript stack traces:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MifYx-CLHjLC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25cd7d67-6793-44dc-cef4-faa5906fa59a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ---------------------------------------------------------------------------  \n",
            "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  Source Location                                                              \n",
            "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ---------------------------------------------------------------------------  \n",
            "                     aten::conv2d         0.00%       9.000us         3.96%      21.157ms      21.157ms             1  <built-in method conv2d of type object at 0x7f8c9936a420>                    \n",
            "                                                                                                                       torch/nn/modules/conv.py(454): _conv_forward                                 \n",
            "                                                                                                                       torch/nn/modules/conv.py(462): forward                                       \n",
            "                                                                                                                       nn.Module: Conv2d_0                                                          \n",
            "                                                                                                                       torchvision/models/resnet.py(266): _forward_impl                             \n",
            "                                                                                                                                                                                                    \n",
            "                aten::convolution         0.01%      40.000us         3.96%      21.148ms      21.148ms             1  <built-in method conv2d of type object at 0x7f8c9936a420>                    \n",
            "                                                                                                                       torch/nn/modules/conv.py(454): _conv_forward                                 \n",
            "                                                                                                                       torch/nn/modules/conv.py(462): forward                                       \n",
            "                                                                                                                       nn.Module: Conv2d_0                                                          \n",
            "                                                                                                                       torchvision/models/resnet.py(266): _forward_impl                             \n",
            "                                                                                                                                                                                                    \n",
            "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ---------------------------------------------------------------------------  \n",
            "Self CPU time total: 534.470ms\n",
            "\n"
          ]
        }
      ],
      "source": [
        "with profile(\n",
        "    activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
        "    with_stack=True,\n",
        ") as prof:\n",
        "    model(inputs)\n",
        "\n",
        "# Print aggregated stats\n",
        "print(prof.key_averages(group_by_stack_n=5).table(sort_by=\"self_cuda_time_total\", row_limit=2))\n",
        "\n",
        "# (omitting some columns)\n",
        "# -------------------------  -----------------------------------------------------------\n",
        "#                      Name  Source Location\n",
        "# -------------------------  -----------------------------------------------------------\n",
        "# aten::thnn_conv2d_forward  .../torch/nn/modules/conv.py(439): _conv_forward\n",
        "#                            .../torch/nn/modules/conv.py(443): forward\n",
        "#                            .../torch/nn/modules/module.py(1051): _call_impl\n",
        "#                            .../site-packages/torchvision/models/resnet.py(63): forward\n",
        "#                            .../torch/nn/modules/module.py(1051): _call_impl\n",
        "#\n",
        "# aten::thnn_conv2d_forward  .../torch/nn/modules/conv.py(439): _conv_forward\n",
        "#                            .../torch/nn/modules/conv.py(443): forward\n",
        "#                            .../torch/nn/modules/module.py(1051): _call_impl\n",
        "#                            .../site-packages/torchvision/models/resnet.py(59): forward\n",
        "#                            .../torch/nn/modules/module.py(1051): _call_impl\n",
        "#\n",
        "# -------------------------  -----------------------------------------------------------\n",
        "# Self CPU time total: 34.016ms\n",
        "# Self CUDA time total: 11.659ms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzOK27Z1HjLD"
      },
      "source": [
        "Note the two convolutions and the two callsites in ``torchvision/models/resnet.py`` script.\n",
        "\n",
        "(Warning: stack tracing adds an extra profiling overhead.)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8egiYA_HjLE"
      },
      "source": [
        "### 7. Visualizing data as a flamegraph\n",
        "\n",
        "Execution time (``self_cpu_time_total`` and ``self_cuda_time_total`` metrics) and stack traces\n",
        "can also be visualized as a flame graph. To do this, first export the raw data using ``export_stacks`` (requires ``with_stack=True``):\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xwvvb7k7HjLF"
      },
      "outputs": [],
      "source": [
        "prof.export_stacks(\"/tmp/profiler_stacks.txt\", \"self_cuda_time_total\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AL1al1QoHjLG"
      },
      "source": [
        "We recommend using e.g. [Flamegraph tool](https://github.com/brendangregg/FlameGraph) to generate an\n",
        "interactive SVG:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEs2Vth0HjLH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb24666c-ff7c-4ead-9fcf-598a85414bef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'FlameGraph'...\n",
            "remote: Enumerating objects: 1217, done.\u001b[K\n",
            "remote: Counting objects: 100% (81/81), done.\u001b[K\n",
            "remote: Compressing objects: 100% (49/49), done.\u001b[K\n",
            "remote: Total 1217 (delta 43), reused 59 (delta 32), pack-reused 1136\u001b[K\n",
            "Receiving objects: 100% (1217/1217), 1.93 MiB | 6.21 MiB/s, done.\n",
            "Resolving deltas: 100% (700/700), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/brendangregg/FlameGraph\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd FlameGraph"
      ],
      "metadata": {
        "id": "JEdmk2xlJu5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyHKA6PHJ5RH",
        "outputId": "bd754721-7f44-4852-8a6a-f2ccf9dbdb6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./flamegraph.pl --title \"CUDA time\" --countname \"us.\" /tmp/profiler_stacks.txt > perf_viz.svg"
      ],
      "metadata": {
        "id": "931TXQA2Isnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-j9_9MZHjLI"
      },
      "source": [
        "<img src=\"file://../../_static/img/perf_viz.png\" scale=\"25 %\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GxJ5P5xHjLJ"
      },
      "source": [
        "### 8. Using profiler to analyze long-running jobs\n",
        "\n",
        "PyTorch profiler offers an additional API to handle long-running jobs\n",
        "(such as training loops). Tracing all of the execution can be\n",
        "slow and result in very large trace files. To avoid this, use optional\n",
        "arguments:\n",
        "\n",
        "- ``schedule`` - specifies a function that takes an integer argument (step number)\n",
        "  as an input and returns an action for the profiler, the best way to use this parameter\n",
        "  is to use ``torch.profiler.schedule`` helper function that can generate a schedule for you;\n",
        "- ``on_trace_ready`` - specifies a function that takes a reference to the profiler as\n",
        "  an input and is called by the profiler each time the new trace is ready.\n",
        "\n",
        "To illustrate how the API works, let's first consider the following example with\n",
        "``torch.profiler.schedule`` helper function:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MwwMVzTHjLL"
      },
      "outputs": [],
      "source": [
        "from torch.profiler import schedule\n",
        "\n",
        "my_schedule = schedule(\n",
        "    skip_first=10,\n",
        "    wait=5,\n",
        "    warmup=1,\n",
        "    active=3,\n",
        "    repeat=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DY4FeLoUHjLM"
      },
      "source": [
        "Profiler assumes that the long-running job is composed of steps, numbered\n",
        "starting from zero. The example above defines the following sequence of actions\n",
        "for the profiler:\n",
        "\n",
        "1. Parameter ``skip_first`` tells profiler that it should ignore the first 10 steps\n",
        "   (default value of ``skip_first`` is zero);\n",
        "2. After the first ``skip_first`` steps, profiler starts executing profiler cycles;\n",
        "3. Each cycle consists of three phases:\n",
        "\n",
        "   - idling (``wait=5`` steps), during this phase profiler is not active;\n",
        "   - warming up (``warmup=1`` steps), during this phase profiler starts tracing, but\n",
        "     the results are discarded; this phase is used to discard the samples obtained by\n",
        "     the profiler at the beginning of the trace since they are usually skewed by an extra\n",
        "     overhead;\n",
        "   - active tracing (``active=3`` steps), during this phase profiler traces and records data;\n",
        "4. An optional ``repeat`` parameter specifies an upper bound on the number of cycles.\n",
        "   By default (zero value), profiler will execute cycles as long as the job runs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaT8crWFHjLN"
      },
      "source": [
        "Thus, in the example above, profiler will skip the first 15 steps, spend the next step on the warm up,\n",
        "actively record the next 3 steps, skip another 5 steps, spend the next step on the warm up, actively\n",
        "record another 3 steps. Since the ``repeat=2`` parameter value is specified, the profiler will stop\n",
        "the recording after the first two cycles.\n",
        "\n",
        "At the end of each cycle profiler calls the specified ``on_trace_ready`` function and passes itself as\n",
        "an argument. This function is used to process the new trace - either by obtaining the table output or\n",
        "by saving the output on disk as a trace file.\n",
        "\n",
        "To send the signal to the profiler that the next step has started, call ``prof.step()`` function.\n",
        "The current profiler step is stored in ``prof.step_num``.\n",
        "\n",
        "The following example shows how to use all of the concepts above:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YjiDWYFHjLO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b4e185b-0526-41da-9d1f-ef8a8670ebb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
            "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                      aten::zeros         0.00%      19.000us         0.01%      30.000us      15.000us             2  \n",
            "                      aten::empty         0.15%     822.000us         0.15%     822.000us       2.035us           404  \n",
            "                      aten::zero_         0.00%       2.000us         0.00%       2.000us       1.000us             2  \n",
            "                    ProfilerStep*         1.11%       6.040ms        99.99%     543.961ms     271.981ms             2  \n",
            "                     aten::conv2d         0.03%     145.000us        68.41%     372.160ms       9.304ms            40  \n",
            "                aten::convolution         0.10%     534.000us        68.38%     372.015ms       9.300ms            40  \n",
            "               aten::_convolution         0.07%     359.000us        68.28%     371.481ms       9.287ms            40  \n",
            "         aten::mkldnn_convolution        68.13%     370.661ms        68.22%     371.122ms       9.278ms            40  \n",
            "                aten::as_strided_         0.02%      88.000us         0.02%      88.000us       2.200us            40  \n",
            "                       aten::add_         0.68%       3.688ms         0.68%       3.688ms      65.857us            56  \n",
            "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 544.025ms\n",
            "\n",
            "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
            "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                      aten::zeros         0.00%      17.000us         0.01%      29.000us      14.500us             2  \n",
            "                      aten::empty         0.13%     674.000us         0.13%     674.000us       1.668us           404  \n",
            "                      aten::zero_         0.00%       2.000us         0.00%       2.000us       1.000us             2  \n",
            "                    ProfilerStep*         1.13%       6.048ms        99.99%     534.397ms     267.199ms             2  \n",
            "                     aten::conv2d         0.02%     132.000us        67.32%     359.763ms       8.994ms            40  \n",
            "                aten::convolution         0.10%     529.000us        67.29%     359.631ms       8.991ms            40  \n",
            "               aten::_convolution         0.06%     329.000us        67.19%     359.102ms       8.978ms            40  \n",
            "         aten::mkldnn_convolution        67.05%     358.342ms        67.13%     358.773ms       8.969ms            40  \n",
            "                aten::as_strided_         0.02%      86.000us         0.02%      86.000us       2.150us            40  \n",
            "                       aten::add_         0.75%       4.001ms         0.75%       4.001ms      71.446us            56  \n",
            "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 534.444ms\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def trace_handler(p):\n",
        "    output = p.key_averages().table(sort_by=\"self_cuda_time_total\", row_limit=10)\n",
        "    print(output)\n",
        "    p.export_chrome_trace(\"/tmp/trace_\" + str(p.step_num) + \".json\")\n",
        "\n",
        "with profile(\n",
        "    activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
        "    schedule=torch.profiler.schedule(\n",
        "        wait=1,\n",
        "        warmup=1,\n",
        "        active=2),\n",
        "    on_trace_ready=trace_handler\n",
        ") as p:\n",
        "    for idx in range(8):\n",
        "        model(inputs)\n",
        "        p.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DMY97zMHjLQ"
      },
      "source": [
        "## Learn More\n",
        "\n",
        "Take a look at the following recipes/tutorials to continue your learning:\n",
        "\n",
        "-  [PyTorch Benchmark](https://pytorch.org/tutorials/recipes/recipes/benchmark.html)\n",
        "-  [PyTorch Profiler with TensorBoard](https://pytorch.org/tutorials/intermediate/tensorboard_profiler_tutorial.html) tutorial\n",
        "-  [Visualizing models, data, and training with TensorBoard](https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html) tutorial\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J8r7VGngK2pM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qy7UjJ1-K2cN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Profiling**"
      ],
      "metadata": {
        "id": "tBjHPwkGGf0N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "\n",
        "model = models.densenet121(pretrained=True)\n",
        "x = torch.randn((1, 3, 224, 224), requires_grad=True)\n",
        "\n",
        "with torch.autograd.profiler.profile(use_cuda=True) as prof:\n",
        "    model(x)\n",
        "print(prof) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "bdb1007cff174672aad23d14cbb1c818",
            "3c4424abb80e4edfb37b37f70611fda7",
            "11ca8f350e944755ad1a6b1cc7db2ec6",
            "4c1657f8370c436cbf219654ec1d2abd",
            "2cf862b2c86841a8be68c65c80e8de9d",
            "c2cb054b59f74519b33275e230f40026",
            "14b4759a08ce4de798bf42df908332d5",
            "e7add3c06789414eb0726547b3c9b9c8",
            "56db207cd7d040929f13bbdd8aaaf381",
            "d8f4940dcc5146a5963af31f7c685126",
            "076df2e8c9304f26be31c4496bc32bec"
          ]
        },
        "id": "u7OR2tMSGeGd",
        "outputId": "474b74cf-18cb-45e3-91a6-d476301db257"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/30.8M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bdb1007cff174672aad23d14cbb1c818"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                     aten::conv2d         0.02%     338.000us         7.47%     103.032ms     103.032ms     344.000us         0.02%     103.048ms     103.048ms             1  \n",
            "                aten::convolution         0.16%       2.212ms         7.45%     102.694ms     102.694ms       2.212ms         0.16%     102.704ms     102.704ms             1  \n",
            "               aten::_convolution         0.27%       3.763ms         7.29%     100.482ms     100.482ms       3.761ms         0.27%     100.492ms     100.492ms             1  \n",
            "         aten::mkldnn_convolution         7.01%      96.654ms         7.02%      96.719ms      96.719ms      96.633ms         6.94%      96.731ms      96.731ms             1  \n",
            "                      aten::empty         0.00%      11.000us         0.00%      11.000us      11.000us      27.000us         0.00%      27.000us      27.000us             1  \n",
            "                      aten::empty         0.00%      36.000us         0.00%      36.000us      36.000us      45.000us         0.00%      45.000us      45.000us             1  \n",
            "                aten::as_strided_         0.00%      18.000us         0.00%      18.000us      18.000us      26.000us         0.00%      26.000us      26.000us             1  \n",
            "                       aten::add_         0.25%       3.491ms         0.25%       3.491ms       3.491ms       3.526ms         0.25%       3.526ms       3.526ms             1  \n",
            "                 aten::batch_norm         0.00%      23.000us         0.71%       9.801ms       9.801ms      24.000us         0.00%       9.809ms       9.809ms             1  \n",
            "     aten::_batch_norm_impl_index         0.22%       3.039ms         0.71%       9.778ms       9.778ms       3.019ms         0.22%       9.785ms       9.785ms             1  \n",
            "                      aten::empty         0.00%       6.000us         0.00%       6.000us       6.000us      12.000us         0.00%      12.000us      12.000us             1  \n",
            "          aten::native_batch_norm         0.49%       6.689ms         0.49%       6.733ms       6.733ms       6.663ms         0.48%       6.754ms       6.754ms             1  \n",
            "                      aten::empty         0.00%       6.000us         0.00%       6.000us       6.000us      12.000us         0.00%      12.000us      12.000us             1  \n",
            "                      aten::empty         0.00%       1.000us         0.00%       1.000us       1.000us       9.000us         0.00%       9.000us       9.000us             1  \n",
            "                      aten::empty         0.00%       1.000us         0.00%       1.000us       1.000us       7.000us         0.00%       7.000us       7.000us             1  \n",
            "                      aten::empty         0.00%       1.000us         0.00%       1.000us       1.000us       7.000us         0.00%       7.000us       7.000us             1  \n",
            "                 aten::empty_like         0.00%      24.000us         0.00%      33.000us      33.000us      23.000us         0.00%      40.000us      40.000us             1  \n",
            "                      aten::empty         0.00%       9.000us         0.00%       9.000us       9.000us      17.000us         0.00%      17.000us      17.000us             1  \n",
            "                      aten::empty         0.00%       1.000us         0.00%       1.000us       1.000us       8.000us         0.00%       8.000us       8.000us             1  \n",
            "                      aten::empty         0.00%       1.000us         0.00%       1.000us       1.000us       8.000us         0.00%       8.000us       8.000us             1  \n",
            "                      aten::relu_         0.12%       1.687ms         0.53%       7.257ms       7.257ms       1.667ms         0.12%       7.267ms       7.267ms             1  \n",
            "                 aten::clamp_min_         0.40%       5.570ms         0.40%       5.570ms       5.570ms       5.600ms         0.40%       5.600ms       5.600ms             1  \n",
            "                 aten::max_pool2d         0.01%     108.000us         1.82%      25.080ms      25.080ms      82.000us         0.01%      25.088ms      25.088ms             1  \n",
            "    aten::max_pool2d_with_indices         1.81%      24.972ms         1.81%      24.972ms      24.972ms      25.006ms         1.79%      25.006ms      25.006ms             1  \n",
            "                        aten::cat         0.54%       7.498ms         0.54%       7.498ms       7.498ms       7.529ms         0.54%       7.529ms       7.529ms             1  \n",
            "                       aten::add_         0.00%      32.000us         0.00%      32.000us      32.000us      40.000us         0.00%      40.000us      40.000us             1  \n",
            "                 aten::batch_norm         0.00%      18.000us         0.11%       1.512ms       1.512ms      17.000us         0.00%       1.517ms       1.517ms             1  \n",
            "     aten::_batch_norm_impl_index         0.00%      62.000us         0.11%       1.494ms       1.494ms      31.000us         0.00%       1.500ms       1.500ms             1  \n",
            "                      aten::empty         0.00%       8.000us         0.00%       8.000us       8.000us      14.000us         0.00%      14.000us      14.000us             1  \n",
            "          aten::native_batch_norm         0.10%       1.372ms         0.10%       1.424ms       1.424ms       1.365ms         0.10%       1.455ms       1.455ms             1  \n",
            "                      aten::empty         0.00%       4.000us         0.00%       4.000us       4.000us       9.000us         0.00%       9.000us       9.000us             1  \n",
            "                      aten::empty         0.00%       1.000us         0.00%       1.000us       1.000us       6.000us         0.00%       6.000us       6.000us             1  \n",
            "                      aten::empty         0.00%       3.000us         0.00%       3.000us       3.000us       8.000us         0.00%       8.000us       8.000us             1  \n",
            "                      aten::empty         0.00%       1.000us         0.00%       1.000us       1.000us       6.000us         0.00%       6.000us       6.000us             1  \n",
            "                 aten::empty_like         0.00%      27.000us         0.00%      41.000us      41.000us      26.000us         0.00%      47.000us      47.000us             1  \n",
            "                      aten::empty         0.00%      14.000us         0.00%      14.000us      14.000us      21.000us         0.00%      21.000us      21.000us             1  \n",
            "                      aten::empty         0.00%       1.000us         0.00%       1.000us       1.000us       7.000us         0.00%       7.000us       7.000us             1  \n",
            "                      aten::empty         0.00%       1.000us         0.00%       1.000us       1.000us       7.000us         0.00%       7.000us       7.000us             1  \n",
            "                      aten::relu_         0.00%      39.000us         0.01%     111.000us     111.000us      53.000us         0.00%     132.000us     132.000us             1  \n",
            "                 aten::clamp_min_         0.01%      72.000us         0.01%      72.000us      72.000us      79.000us         0.01%      79.000us      79.000us             1  \n",
            "                     aten::conv2d         0.00%      19.000us         1.14%      15.766ms      15.766ms      19.000us         0.00%      15.773ms      15.773ms             1  \n",
            "                aten::convolution         0.00%      43.000us         1.14%      15.747ms      15.747ms      38.000us         0.00%      15.754ms      15.754ms             1  \n",
            "               aten::_convolution         0.10%       1.386ms         1.14%      15.704ms      15.704ms       1.365ms         0.10%      15.716ms      15.716ms             1  \n",
            "          aten::_nnpack_available         0.17%       2.393ms         0.17%       2.393ms       2.393ms       2.417ms         0.17%       2.417ms       2.417ms             1  \n",
            "                aten::thnn_conv2d         0.01%      81.000us         0.87%      11.925ms      11.925ms      60.000us         0.00%      11.934ms      11.934ms             1  \n",
            "       aten::_slow_conv2d_forward         0.86%      11.815ms         0.86%      11.844ms      11.844ms      11.810ms         0.85%      11.874ms      11.874ms             1  \n",
            "                      aten::empty         0.00%       5.000us         0.00%       5.000us       5.000us      11.000us         0.00%      11.000us      11.000us             1  \n",
            "                       aten::view         0.00%       6.000us         0.00%       6.000us       6.000us      13.000us         0.00%      13.000us      13.000us             1  \n",
            "                       aten::view         0.00%       1.000us         0.00%       1.000us       1.000us      11.000us         0.00%      11.000us      11.000us             1  \n",
            "                     aten::detach         0.00%       3.000us         0.00%       3.000us       3.000us       9.000us         0.00%       9.000us       9.000us             1  \n",
            "                    aten::resize_         0.00%      14.000us         0.00%      14.000us      14.000us      20.000us         0.00%      20.000us      20.000us             1  \n",
            "                       aten::add_         0.00%      17.000us         0.00%      17.000us      17.000us      25.000us         0.00%      25.000us      25.000us             1  \n",
            "                 aten::batch_norm         0.00%      27.000us         0.22%       3.047ms       3.047ms      24.000us         0.00%       3.053ms       3.053ms             1  \n",
            "     aten::_batch_norm_impl_index         0.00%      49.000us         0.22%       3.020ms       3.020ms      35.000us         0.00%       3.029ms       3.029ms             1  \n",
            "                      aten::empty         0.00%       3.000us         0.00%       3.000us       3.000us      11.000us         0.00%      11.000us      11.000us             1  \n",
            "          aten::native_batch_norm         0.21%       2.907ms         0.22%       2.968ms       2.968ms       2.871ms         0.21%       2.983ms       2.983ms             1  \n",
            "                      aten::empty         0.00%       2.000us         0.00%       2.000us       2.000us       9.000us         0.00%       9.000us       9.000us             1  \n",
            "                      aten::empty         0.00%       4.000us         0.00%       4.000us       4.000us      11.000us         0.00%      11.000us      11.000us             1  \n",
            "                      aten::empty         0.00%       1.000us         0.00%       1.000us       1.000us       8.000us         0.00%       8.000us       8.000us             1  \n",
            "                      aten::empty         0.00%      10.000us         0.00%      10.000us      10.000us      18.000us         0.00%      18.000us      18.000us             1  \n",
            "                 aten::empty_like         0.00%      21.000us         0.00%      41.000us      41.000us      21.000us         0.00%      48.000us      48.000us             1  \n",
            "                      aten::empty         0.00%      20.000us         0.00%      20.000us      20.000us      27.000us         0.00%      27.000us      27.000us             1  \n",
            "                      aten::empty         0.00%       2.000us         0.00%       2.000us       2.000us       9.000us         0.00%       9.000us       9.000us             1  \n",
            "                      aten::empty         0.00%       1.000us         0.00%       1.000us       1.000us       9.000us         0.00%       9.000us       9.000us             1  \n",
            "                      aten::relu_         0.00%      36.000us         0.01%     179.000us     179.000us      32.000us         0.00%     186.000us     186.000us             1  \n",
            "                 aten::clamp_min_         0.01%     143.000us         0.01%     143.000us     143.000us     154.000us         0.01%     154.000us     154.000us             1  \n",
            "                     aten::conv2d         0.00%      25.000us         1.80%      24.851ms      24.851ms      26.000us         0.00%      24.860ms      24.860ms             1  \n",
            "                aten::convolution         0.00%      35.000us         1.80%      24.826ms      24.826ms      35.000us         0.00%      24.834ms      24.834ms             1  \n",
            "               aten::_convolution         0.00%      31.000us         1.80%      24.791ms      24.791ms      29.000us         0.00%      24.799ms      24.799ms             1  \n",
            "         aten::mkldnn_convolution         1.79%      24.742ms         1.80%      24.760ms      24.760ms      24.722ms         1.77%      24.770ms      24.770ms             1  \n",
            "                      aten::empty         0.00%       3.000us         0.00%       3.000us       3.000us      14.000us         0.00%      14.000us      14.000us             1  \n",
            "                      aten::empty         0.00%      10.000us         0.00%      10.000us      10.000us      21.000us         0.00%      21.000us      21.000us             1  \n",
            "                aten::as_strided_         0.00%       5.000us         0.00%       5.000us       5.000us      13.000us         0.00%      13.000us      13.000us             1  \n",
            "                        aten::cat         0.01%     163.000us         0.01%     163.000us     163.000us     176.000us         0.01%     176.000us     176.000us             1  \n",
            "                       aten::add_         0.00%      16.000us         0.00%      16.000us      16.000us      22.000us         0.00%      22.000us      22.000us             1  \n",
            "                 aten::batch_norm         0.00%      17.000us         0.13%       1.859ms       1.859ms      16.000us         0.00%       1.864ms       1.864ms             1  \n",
            "     aten::_batch_norm_impl_index         0.00%      41.000us         0.13%       1.842ms       1.842ms      28.000us         0.00%       1.848ms       1.848ms             1  \n",
            "                      aten::empty         0.00%       2.000us         0.00%       2.000us       2.000us       7.000us         0.00%       7.000us       7.000us             1  \n",
            "          aten::native_batch_norm         0.13%       1.758ms         0.13%       1.799ms       1.799ms       1.734ms         0.12%       1.813ms       1.813ms             1  \n",
            "                      aten::empty         0.00%       1.000us         0.00%       1.000us       1.000us       7.000us         0.00%       7.000us       7.000us             1  \n",
            "                      aten::empty         0.00%       1.000us         0.00%       1.000us       1.000us       6.000us         0.00%       6.000us       6.000us             1  \n",
            "                      aten::empty         0.00%       1.000us         0.00%       1.000us       1.000us       6.000us         0.00%       6.000us       6.000us             1  \n",
            "                      aten::empty         0.00%       1.000us         0.00%       1.000us       1.000us       7.000us         0.00%       7.000us       7.000us             1  \n",
            "                 aten::empty_like         0.00%      18.000us         0.00%      35.000us      35.000us      16.000us         0.00%      40.000us      40.000us             1  \n",
            "                      aten::empty         0.00%      17.000us         0.00%      17.000us      17.000us      24.000us         0.00%      24.000us      24.000us             1  \n",
            "                      aten::empty         0.00%       1.000us         0.00%       1.000us       1.000us       7.000us         0.00%       7.000us       7.000us             1  \n",
            "                      aten::empty         0.00%       1.000us         0.00%       1.000us       1.000us       6.000us         0.00%       6.000us       6.000us             1  \n",
            "                      aten::relu_         0.00%      29.000us         0.01%     124.000us     124.000us      28.000us         0.00%     130.000us     130.000us             1  \n",
            "                 aten::clamp_min_         0.01%      95.000us         0.01%      95.000us      95.000us     102.000us         0.01%     102.000us     102.000us             1  \n",
            "                     aten::conv2d         0.00%      17.000us         0.91%      12.532ms      12.532ms      17.000us         0.00%      12.539ms      12.539ms             1  \n",
            "                aten::convolution         0.00%      29.000us         0.91%      12.515ms      12.515ms      29.000us         0.00%      12.522ms      12.522ms             1  \n",
            "               aten::_convolution         0.00%      40.000us         0.91%      12.486ms      12.486ms      35.000us         0.00%      12.493ms      12.493ms             1  \n",
            "          aten::_nnpack_available         0.00%       1.000us         0.00%       1.000us       1.000us       6.000us         0.00%       6.000us       6.000us             1  \n",
            "                aten::thnn_conv2d         0.00%      40.000us         0.90%      12.445ms      12.445ms      19.000us         0.00%      12.452ms      12.452ms             1  \n",
            "       aten::_slow_conv2d_forward         0.90%      12.382ms         0.90%      12.405ms      12.405ms      12.372ms         0.89%      12.433ms      12.433ms             1  \n",
            "                      aten::empty         0.00%       3.000us         0.00%       3.000us       3.000us       8.000us         0.00%       8.000us       8.000us             1  \n",
            "                       aten::view         0.00%       4.000us         0.00%       4.000us       4.000us      10.000us         0.00%      10.000us      10.000us             1  \n",
            "                       aten::view         0.00%       1.000us         0.00%       1.000us       1.000us      16.000us         0.00%      16.000us      16.000us             1  \n",
            "                     aten::detach         0.00%       2.000us         0.00%       2.000us       2.000us       8.000us         0.00%       8.000us       8.000us             1  \n",
            "                    aten::resize_         0.00%      13.000us         0.00%      13.000us      13.000us      19.000us         0.00%      19.000us      19.000us             1  \n",
            "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 1.378s\n",
            "Self CUDA time total: 1.393s\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iOKBud13HXYs"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6NhyE5o5LyAM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}